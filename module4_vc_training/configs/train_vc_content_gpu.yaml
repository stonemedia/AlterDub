data:
  train_list: D:/AlterDub/module3_dataset/metadata/train_list.txt
  val_list:   D:/AlterDub/module3_dataset/metadata/val_list.txt
  segment_frames: 192
  num_workers: 8
  pin_memory: true

model:
  n_mels: 80
  content_dim: 256
  spk_emb_dim: 128
  f0_emb_dim: 32
  hidden_dim: 256
  num_decoder_layers: 4
  dropout: 0.1
  num_speakers: 4   # <-- set correctly
  causal: true

  # decoder mode (weâ€™ll add this in step 3)

training:
  batch_size: 32
  num_epochs: 999999
  learning_rate: 0.0002
  weight_decay: 0.0
  grad_clip: 1.0
  optimizer: "adamw"
  scheduler: "none"

  use_amp: true

  log_every_steps: 50
  val_every_steps: 1000
  save_every_steps: 1000
  max_steps: 200000

loss:
  w_mel: 1.0

checkpoint:
  out_dir: "D:/AlterDub/module4_vc_training/checkpoints"
  keep_last_n: 5

logging:
  use_tensorboard: true
  log_dir: "D:/AlterDub/module4_vc_training/logs/tensorboard"
  run_name: "vc_content_encoder_gpu"

device:
  use_cuda: true
  gpu_id: 0
  seed: 42
